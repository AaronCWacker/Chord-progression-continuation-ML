# Generating Chord Progressions
This is a repository for an ongoing project of mine where I try to generate believable chord progression continuations from a prompt. The idea is that if I provide the model with, for instance, a few chords like *Am7 - Dm*, it would output *EM7 - Am* - a standard logical continuation. The main issue here is, of course, making the model learn the musical context (tonality,  harmonic diversity, etc.) and understand the long-term structure of music. To that end, I've developed three models so far: one employing bidirectional LSTMs, one using [Perceiver AR](https://www.deepmind.com/publications/perceiver-ar-general-purpose-long-context-autoregressive-generation) (a long-context autoregressive model), and one using GPT2 and treating the chords as text. I've also written a short script that extracts chords from MIDI files to serve as the source of data for the models. 

## Chord Extraction
I've written a short script based on the [Chorder package](https://github.com/joshuachang2311/chorder) that extracts chords from MIDI files. The script is available in the *MIDI_to_chords.ipynb* notebook. I've used this script and the [Lakh MIDI dataset](https://colinraffel.com/projects/lmd/) to download and 'chordify' songs of over 250 Soul artists (via a manually compiled list), giving me chords from over 1700 songs. These chords were used as the data for all three models below. The data is available for download as a .txt or as a pickle file.

## LSTM
The code can be found in the *chord_progrression_LSTM.ipynb* notebook. The results are rather mixed: the model tends to suggest only the most basic chords (*I* or *V*), which do make some sense, but do not quite reflect the diversity of chord progressions in real-world music. Making the model's suggestions "hotter" is a hit-or-miss: sometimes they are quite fitting, but sometimes they are as dissonant as they can get. I tried creating my own embeddings for the chords (representing them as constituent pitches), but that provided only marginal improvement to the model's performance.

## GPT2
Better results are achieved with GPT2, thanks to the model's sophisticated architecture (i.e. implementation of attention). The code is available in the *chord_progrression_GPT2.ipynb* notebook. However, the results are still not quite stellar: progressions seem to get off-key rather quickly. Though, to be fair, some of them are quite pleasant. 

## Perceiver AR
My current approach utilizes a brand new architecture - [Perceiver AR](https://www.deepmind.com/publications/perceiver-ar-general-purpose-long-context-autoregressive-generation), developed by the Deep Mind team and implemented in PyTorch by [Phil Wang on GitHub](https://github.com/lucidrains/perceiver-ar-pytorch).  This auto-regressive model is able to attend to very long context windows and generate outputs with long-term coherence. So far I haven't managed to properly fine-tune the model parameters for this specific task and the model is prone to overfitting, but the results are encouraging nonetheless.
